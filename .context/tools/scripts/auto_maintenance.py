#!/usr/bin/env python3
"""
Auto Maintenance Script - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –≤ –°–õ–ö

–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –∑–∞–¥–∞—á–∏:
- –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
- –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö backup'–æ–≤
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤

–í–µ—Ä—Å–∏—è: 1.0.0
–°–æ–∑–¥–∞–Ω–æ: 2025-01-15
"""

import sys
import time
import json
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from tools.cli_modules.core.file_organization_engine import FileOrganizationEngine, AutoCleanupSystem
    from tools.cli_modules.core.unified_context_engine import UnifiedContextEngine
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
    FileOrganizationEngine = None
    UnifiedContextEngine = None


class AutoMaintenanceSystem:
    """–°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞"""
    
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
        self.config_file = self.base_path / ".slc" / "maintenance_config.json"
        self.log_file = self.base_path / ".slc" / "maintenance_log.json"
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—ã
        self.file_org = FileOrganizationEngine(base_path) if FileOrganizationEngine else None
        self.cleanup_system = AutoCleanupSystem(base_path) if AutoCleanupSystem else None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = self._load_config()
        
    def _load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
        default_config = {
            "auto_organize_enabled": True,
            "auto_cleanup_enabled": True,
            "organization_interval_hours": 6,
            "cleanup_interval_hours": 24,
            "max_project_size_mb": 1024,  # 1GB
            "backup_retention_days": 30,
            "generate_reports": True,
            "verbose_logging": False
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    return {**default_config, **json.load(f)}
            except Exception:
                pass
        
        return default_config
    
    def run_full_maintenance(self, dry_run: bool = False) -> Dict:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"""
        start_time = time.time()
        
        print("üîß –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è...")
        print("=" * 60)
        
        results = {
            "timestamp": datetime.now().isoformat(),
            "dry_run": dry_run,
            "tasks": {}
        }
        
        # 1. –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
        if self.config["auto_organize_enabled"] and self.file_org:
            print("\nüóÇÔ∏è  –®–∞–≥ 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤")
            org_result = self.file_org.organize_files(dry_run=dry_run)
            results["tasks"]["file_organization"] = {
                "processed_files": org_result.processed_files,
                "moved_files": org_result.moved_files,
                "execution_time": org_result.execution_time,
                "errors": len(org_result.errors)
            }
            print(f"   ‚úÖ –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {org_result.processed_files}")
            print(f"   üìÇ –§–∞–π–ª–æ–≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {org_result.moved_files}")
        
        # 2. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if self.config["auto_cleanup_enabled"] and self.cleanup_system:
            print("\nüßπ –®–∞–≥ 2: –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
            cleanup_result = self.cleanup_system.perform_cleanup(dry_run=dry_run)
            results["tasks"]["cleanup"] = {
                "processed_files": cleanup_result.processed_files,
                "deleted_files": cleanup_result.deleted_files,
                "space_freed": cleanup_result.space_freed,
                "errors": len(cleanup_result.errors)
            }
            print(f"   ‚úÖ –§–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {cleanup_result.processed_files}")
            print(f"   üóëÔ∏è  –§–∞–π–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ: {cleanup_result.deleted_files}")
            print(f"   üíæ –ú–µ—Å—Ç–∞ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ: {self._format_size(cleanup_result.space_freed)}")
        
        # 3. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        print("\nüìä –®–∞–≥ 3: –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞")
        size_analysis = self._analyze_project_size()
        results["tasks"]["size_analysis"] = size_analysis
        print(f"   üìè –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {self._format_size(size_analysis['total_size'])}")
        print(f"   üìÅ –§–∞–π–ª–æ–≤ –≤—Å–µ–≥–æ: {size_analysis['file_count']}")
        print(f"   üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {size_analysis['dir_count']}")
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ä—ã—Ö backup'–æ–≤
        print("\nüì¶ –®–∞–≥ 4: –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ backup —Ñ–∞–π–ª–∞–º–∏")
        backup_analysis = self._manage_backups(dry_run=dry_run)
        results["tasks"]["backup_management"] = backup_analysis
        print(f"   üì¶ Backup —Ñ–∞–π–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {backup_analysis['found_backups']}")
        print(f"   üóëÔ∏è  –°—Ç–∞—Ä—ã—Ö backup —É–¥–∞–ª–µ–Ω–æ: {backup_analysis['deleted_backups']}")
        
        # 5. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
        if self.config["generate_reports"]:
            print("\nüìã –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞")
            report_path = self._generate_maintenance_report(results)
            print(f"   üìÑ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
        
        total_time = time.time() - start_time
        results["total_execution_time"] = total_time
        
        print(f"\nüéâ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_time:.2f}—Å")
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self._log_maintenance_run(results)
        
        return results
    
    def _analyze_project_size(self) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞"""
        total_size = 0
        file_count = 0
        dir_count = 0
        largest_files = []
        
        for path in self.base_path.rglob("*"):
            if path.is_file():
                try:
                    size = path.stat().st_size
                    total_size += size
                    file_count += 1
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—Ä—É–ø–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
                    largest_files.append((str(path.relative_to(self.base_path)), size))
                    
                except Exception:
                    pass
            elif path.is_dir():
                dir_count += 1
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É
        largest_files.sort(key=lambda x: x[1], reverse=True)
        largest_files = largest_files[:10]  # –¢–æ–ø 10
        
        return {
            "total_size": total_size,
            "file_count": file_count,
            "dir_count": dir_count,
            "largest_files": largest_files,
            "size_warning": total_size > (self.config["max_project_size_mb"] * 1024 * 1024)
        }
    
    def _manage_backups(self, dry_run: bool = False) -> Dict:
        """–£–ø—Ä–∞–≤–ª—è–µ—Ç backup —Ñ–∞–π–ª–∞–º–∏"""
        cutoff_date = datetime.now() - timedelta(days=self.config["backup_retention_days"])
        
        backup_patterns = ["backup_*.tar.gz", "*.backup", "*.bak", "*.old"]
        found_backups = 0
        deleted_backups = 0
        
        for pattern in backup_patterns:
            for backup_file in self.base_path.rglob(pattern):
                if backup_file.is_file():
                    found_backups += 1
                    
                    try:
                        file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                        
                        if file_time < cutoff_date:
                            if not dry_run:
                                backup_file.unlink()
                                print(f"   üóëÔ∏è  –£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π backup: {backup_file}")
                            else:
                                print(f"   [DRY RUN] –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–π backup: {backup_file}")
                            
                            deleted_backups += 1
                            
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {backup_file}: {e}")
        
        return {
            "found_backups": found_backups,
            "deleted_backups": deleted_backups,
            "retention_days": self.config["backup_retention_days"]
        }
    
    def _generate_maintenance_report(self, results: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –æ–± –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–∏"""
        report_dir = self.base_path / ".slc" / "reports"
        report_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = report_dir / f"maintenance_report_{timestamp}.json"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        enhanced_report = {
            **results,
            "config": self.config,
            "recommendations": self._generate_recommendations(results)
        }
        
        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(enhanced_report, f, indent=2, ensure_ascii=False)
            
            return str(report_file.relative_to(self.base_path))
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á—ë—Ç–∞: {e}")
            return ""
    
    def _generate_recommendations(self, results: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        recommendations = []
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞
        size_analysis = results["tasks"].get("size_analysis", {})
        if size_analysis.get("size_warning"):
            recommendations.append(
                f"‚ö†Ô∏è  –†–∞–∑–º–µ—Ä –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç {self.config['max_project_size_mb']}MB. "
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—á–∏—Å—Ç–∫–∞ –∏–ª–∏ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ."
            )
        
        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤–æ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
        org_task = results["tasks"].get("file_organization", {})
        if org_task.get("moved_files", 0) > 10:
            recommendations.append(
                "üìÇ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –º–Ω–æ–≥–æ –Ω–µ–æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤. "
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª."
            )
        
        # –ê–Ω–∞–ª–∏–∑ backup'–æ–≤
        backup_task = results["tasks"].get("backup_management", {})
        if backup_task.get("found_backups", 0) > 5:
            recommendations.append(
                "üì¶ –ù–∞–π–¥–µ–Ω–æ –º–Ω–æ–≥–æ backup —Ñ–∞–π–ª–æ–≤. "
                "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∞—Ä—Ö–∏–≤–∞—Ü–∏–∏."
            )
        
        if not recommendations:
            recommendations.append("‚úÖ –ü—Ä–æ–µ–∫—Ç –≤ —Ö–æ—Ä–æ—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        
        return recommendations
    
    def _log_maintenance_run(self, results: Dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
        log_entries = []
        
        if self.log_file.exists():
            try:
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    log_entries = json.load(f)
            except Exception:
                pass
        
        log_entries.append(results)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π
        log_entries = log_entries[-50:]
        
        try:
            self.log_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(log_entries, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –ª–æ–≥–∞: {e}")
    
    def _format_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024
        return f"{size_bytes:.1f} TB"
    
    def check_maintenance_needed(self) -> Dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"""
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫
        last_run = self._get_last_maintenance_run()
        
        if not last_run:
            return {
                "maintenance_needed": True,
                "reason": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–æ—Å—å",
                "priority": "high"
            }
        
        last_run_time = datetime.fromisoformat(last_run["timestamp"])
        time_since_last = datetime.now() - last_run_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        org_interval = timedelta(hours=self.config["organization_interval_hours"])
        cleanup_interval = timedelta(hours=self.config["cleanup_interval_hours"])
        
        if time_since_last > cleanup_interval:
            return {
                "maintenance_needed": True,
                "reason": f"–ü—Ä–æ—à–ª–æ {time_since_last.days} –¥–Ω–µ–π —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ—á–∏—Å—Ç–∫–∏",
                "priority": "medium"
            }
        
        if time_since_last > org_interval:
            return {
                "maintenance_needed": True,
                "reason": f"–ü—Ä–æ—à–ª–æ {time_since_last.total_seconds()/3600:.1f} —á–∞—Å–æ–≤ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏",
                "priority": "low"
            }
        
        return {
            "maintenance_needed": False,
            "reason": "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è",
            "next_run": str(last_run_time + cleanup_interval)
        }
    
    def _get_last_maintenance_run(self) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∑–∞–ø—É—Å–∫–µ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è"""
        if not self.log_file.exists():
            return None
        
        try:
            with open(self.log_file, 'r', encoding='utf-8') as f:
                log_entries = json.load(f)
            
            if log_entries:
                return log_entries[-1]
        except Exception:
            pass
        
        return None


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è CLI"""
    parser = argparse.ArgumentParser(
        description="üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –≤ –°–õ–ö",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        "--dry-run", "-n",
        action="store_true",
        help="–¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π"
    )
    
    parser.add_argument(
        "--check-only", "-c",
        action="store_true",
        help="–¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"
    )
    
    parser.add_argument(
        "--force", "-f",
        action="store_true",
        help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ"
    )
    
    parser.add_argument(
        "--config",
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )
    
    args = parser.parse_args()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É
    maintenance = AutoMaintenanceSystem()
    
    if args.check_only:
        # –¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞
        check_result = maintenance.check_maintenance_needed()
        
        if check_result["maintenance_needed"]:
            print(f"üîß –û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è: {check_result['reason']}")
            print(f"üìä –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {check_result['priority']}")
            return 1
        else:
            print(f"‚úÖ {check_result['reason']}")
            if "next_run" in check_result:
                print(f"üìÖ –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: {check_result['next_run']}")
            return 0
    
    else:
        # –ó–∞–ø—É—Å–∫ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è
        if not args.force:
            check_result = maintenance.check_maintenance_needed()
            if not check_result["maintenance_needed"]:
                print(f"üí° {check_result['reason']}")
                print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --force –¥–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞")
                return 0
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
        results = maintenance.run_full_maintenance(dry_run=args.dry_run)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = results.get("recommendations", [])
        if recommendations:
            print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
            for rec in recommendations:
                print(f"   ‚Ä¢ {rec}")
        
        return 0


if __name__ == "__main__":
    exit(main()) 