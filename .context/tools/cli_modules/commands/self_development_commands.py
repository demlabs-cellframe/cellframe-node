#!/usr/bin/env python3
"""
–ö–æ–º–∞–Ω–¥—ã —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è –¥–ª—è Smart Layered Context CLI
–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∂–∏–º —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è, –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á

–í–µ—Ä—Å–∏—è: 1.0.0
–°–æ–∑–¥–∞–Ω–æ: 2025-01-16
"""

import os
import json
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

from tools.cli_modules.common.base_command import BaseCommand
from tools.cli_modules.common.context_output import create_reflection_context, ContextOutputManager


class SelfDevelopmentCommand(BaseCommand):
    """–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∂–∏–º —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á"""
    
    def __init__(self, base_path: str):
        super().__init__()
        self.base_path = Path(base_path)
        self.tasks_dir = self.base_path / 'tasks'
        self.reflection_log = self.base_path / '.slc_reflection_log.json'
        
    @property
    def name(self) -> str:
        return "—Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ"
    
    @property
    def description(self) -> str:
        return "üß† –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∂–∏–º —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è –∏ –∞–Ω–∞–ª–∏–∑–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á"
    
    def add_arguments(self, parser: argparse.ArgumentParser):
        parser.add_argument(
            "--auto-start", 
            action="store_true",
            help="–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑ –±–µ–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
        )
        parser.add_argument(
            "--days-back", 
            type=int, 
            default=7,
            help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–¥–∞—á (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 7)"
        )
        parser.add_argument(
            "--verbose", "-v",
            action="store_true",
            help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞"
        )
        parser.add_argument(
            "--deep",
            action="store_true", 
            help="–ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å –≤—ã—è–≤–ª–µ–Ω–∏–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —É–ª—É—á—à–µ–Ω–∏–π"
        )
        parser.add_argument(
            "--json-context",
            action="store_true",
            help="–í—ã–≤–µ—Å—Ç–∏ JSON —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–ª—è AI –ø–æ–º–æ—â–Ω–∏–∫–∞"
        )
        parser.add_argument(
            "--load-content",
            action="store_true",
            help="–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –≤ JSON –≤—ã–≤–æ–¥"
        )
    
    def execute(self, args: argparse.Namespace) -> int:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è"""
        print("üß† –ó–ê–ü–£–°–ö –†–ï–ñ–ò–ú–ê –°–ê–ú–û–†–ê–ó–í–ò–¢–ò–Ø –°–õ–ö")
        print("=" * 60)
        
        try:
            # 1. –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            current_state = self._analyze_current_state(args.verbose)
            
            # 2. –ü–æ–∏—Å–∫ –Ω–µ–æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
            unreflected_tasks = self._find_unreflected_tasks(args.days_back, args.verbose)
            
            # 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞
            analysis_plan = self._create_analysis_plan(unreflected_tasks, current_state, args.verbose)
            
            # 4. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∑–∞–¥–∞—á–∏ –∞–Ω–∞–ª–∏–∑–∞
            if not args.auto_start:
                print("üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ—Ç–∫–ª—é—á–µ–Ω–∞)")
                print(f"üìã –ë—É–¥–µ—Ç –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–¥–∞—á: {len(unreflected_tasks)}")
                print(f"üîç –û–±–ª–∞—Å—Ç–µ–π –∞–Ω–∞–ª–∏–∑–∞: {len(analysis_plan.get('analysis_areas', []))}")
            
            # 5. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
            analysis_results = self._execute_analysis(analysis_plan, args.deep, args.verbose)
            
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            self._save_analysis_results(analysis_results, args.verbose)
            
            # 7. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ
            self._switch_to_development_context(args.verbose)
            
            print("\nüéâ –ê–ù–ê–õ–ò–ó –°–ê–ú–û–†–ê–ó–í–ò–¢–ò–Ø –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
            print(f"üìä –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–¥–∞—á: {len(unreflected_tasks)}")
            print(f"üß† –°–æ–∑–¥–∞–Ω–æ –∏–Ω—Å–∞–π—Ç–æ–≤: {len(analysis_results.get('insights', []))}")
            print("üöÄ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω –Ω–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ")
            
            # –í—ã–≤–æ–¥–∏–º JSON –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω
            if args.json_context:
                context_output = create_reflection_context(analysis_results, str(self.base_path))
                if args.load_content:
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤
                    manager = ContextOutputManager(str(self.base_path))
                    context_output["context_data"]["files_content"] = manager._load_files_content(
                        context_output["context_data"]["files_to_load"]
                    )
                
                manager = ContextOutputManager(str(self.base_path))
                manager.print_context_output(context_output)
            
            return 0
            
        except Exception as e:
            self.print_error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return 1
    
    def _analyze_current_state(self, verbose: bool) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –°–õ–ö —Å–∏—Å—Ç–µ–º—ã"""
        if verbose:
            print("üìä –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è...")
        
        state = {
            'timestamp': time.time(),
            'tasks_total': 0,
            'tasks_active': 0,
            'tasks_completed': 0,
            'templates_count': 0,
            'last_activity': None
        }
        
        # –ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á
        if self.tasks_dir.exists():
            active_tasks_file = self.tasks_dir / 'active.json'
            if active_tasks_file.exists():
                try:
                    with open(active_tasks_file, 'r', encoding='utf-8') as f:
                        active_data = json.load(f)
                        state['tasks_active'] = len(active_data.get('tasks', []))
                        state['tasks_total'] += state['tasks_active']
                except:
                    pass
            
            completed_dir = self.tasks_dir / 'completed'
            if completed_dir.exists():
                completed_files = list(completed_dir.glob('*.json'))
                state['tasks_completed'] = len(completed_files)
                state['tasks_total'] += state['tasks_completed']
                
                if completed_files:
                    latest_file = max(completed_files, key=lambda f: f.stat().st_mtime)
                    state['last_activity'] = latest_file.stat().st_mtime
        
        if verbose:
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –∑–∞–¥–∞—á: {state['tasks_total']} (–∞–∫—Ç–∏–≤–Ω—ã—Ö: {state['tasks_active']}, –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö: {state['tasks_completed']})")
        
        return state
    
    def _find_unreflected_tasks(self, days_back: int, verbose: bool) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –∑–∞–¥–∞—á, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã"""
        if verbose:
            print(f"üîç –ü–æ–∏—Å–∫ –Ω–µ–æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {days_back} –¥–Ω–µ–π...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª–æ–≥ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
        reflection_log = self._load_reflection_log()
        reflected_task_ids = set(reflection_log.get('reflected_tasks', []))
        
        unreflected = []
        cutoff_time = time.time() - (days_back * 24 * 60 * 60)
        
        # –ò—â–µ–º –≤ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö
        completed_dir = self.tasks_dir / 'completed'
        if completed_dir.exists():
            for task_file in completed_dir.glob('*.json'):
                if task_file.stat().st_mtime < cutoff_time:
                    continue
                
                try:
                    with open(task_file, 'r', encoding='utf-8') as f:
                        task_data = json.load(f)
                        task_id = task_file.stem
                        
                        if task_id not in reflected_task_ids:
                            unreflected.append({
                                'id': task_id,
                                'file_path': str(task_file),
                                'completion_time': task_file.stat().st_mtime,
                                'data': task_data
                            })
                except:
                    continue
        
        if verbose:
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –Ω–µ–æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á: {len(unreflected)}")
            for task in unreflected[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                task_name = task['data'].get('project', task['id'])
                print(f"      ‚Ä¢ {task_name}")
            if len(unreflected) > 3:
                print(f"      ... –∏ –µ—â–µ {len(unreflected) - 3}")
        
        return unreflected
    
    def _create_analysis_plan(self, unreflected_tasks: List[Dict], current_state: Dict, verbose: bool) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è"""
        if verbose:
            print("üìã –°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞...")
        
        plan = {
            'timestamp': time.time(),
            'tasks_to_analyze': unreflected_tasks,
            'analysis_areas': [],
            'questions': [],
            'improvement_opportunities': []
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±–ª–∞—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        if unreflected_tasks:
            plan['analysis_areas'].extend([
                '–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á',
                '–ö–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤',
                '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∏ –º–µ—Ç–æ–¥—ã',
                '–í–æ–∑–Ω–∏–∫—à–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è',
                '–ü–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è –∏ –Ω–∞–≤—ã–∫–∏'
            ])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        plan['questions'].extend([
            '–ö–∞–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É—Å–ø–µ—Ö–∞ –º–æ–∂–Ω–æ –≤—ã–¥–µ–ª–∏—Ç—å?',
            '–ì–¥–µ –µ—Å—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è?',
            '–ö–∞–∫–∏–µ –∑–Ω–∞–Ω–∏—è –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã?',
            '–ö–∞–∫ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—á–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã?'
        ])
        
        if verbose:
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω –ø–ª–∞–Ω –∞–Ω–∞–ª–∏–∑–∞ —Å {len(plan['analysis_areas'])} –æ–±–ª–∞—Å—Ç—è–º–∏")
        
        return plan
    
    def _execute_analysis(self, plan: Dict, deep: bool, verbose: bool) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è"""
        if verbose:
            print("üß† –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è...")
        
        results = {
            'timestamp': time.time(),
            'insights': [],
            'lessons_learned': [],
            'improvement_actions': [],
            'patterns': [],
            'recommendations': []
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –∑–∞–¥–∞—á—É
        for task in plan['tasks_to_analyze']:
            task_insights = self._analyze_task(task, deep, verbose)
            results['insights'].extend(task_insights)
        
        # –ò—â–µ–º –æ–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if deep:
            patterns = self._identify_patterns(plan['tasks_to_analyze'], verbose)
            results['patterns'].extend(patterns)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations = self._generate_recommendations(results, verbose)
        results['recommendations'].extend(recommendations)
        
        if verbose:
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ –∏–Ω—Å–∞–π—Ç–æ–≤: {len(results['insights'])}")
            print(f"   ‚úÖ –í—ã—è–≤–ª–µ–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(results['patterns'])}")
            print(f"   ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(results['recommendations'])}")
        
        return results
    
    def _analyze_task(self, task: Dict, deep: bool, verbose: bool) -> List[Dict[str, Any]]:
        """–ê–Ω–∞–ª–∏–∑ –æ—Ç–¥–µ–ª—å–Ω–æ–π –∑–∞–¥–∞—á–∏"""
        insights = []
        
        task_data = task['data']
        task_name = task_data.get('project', task['id'])
        
        # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        insight = {
            'task_id': task['id'],
            'task_name': task_name,
            'type': 'task_analysis',
            'completion_time': task['completion_time'],
            'analysis': {
                'project_type': task_data.get('project_type', 'unknown'),
                'status': task_data.get('status', 'unknown'),
                'duration': self._calculate_task_duration(task_data),
                'complexity': self._assess_complexity(task_data)
            }
        }
        
        insights.append(insight)
        
        return insights
    
    def _identify_patterns(self, tasks: List[Dict], verbose: bool) -> List[Dict[str, Any]]:
        """–í—ã—è–≤–ª–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö"""
        patterns = []
        
        if not tasks:
            return patterns
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –ø—Ä–æ–µ–∫—Ç–æ–≤
        project_types = {}
        for task in tasks:
            project_type = task['data'].get('project_type', 'unknown')
            if project_type not in project_types:
                project_types[project_type] = 0
            project_types[project_type] += 1
        
        if project_types:
            patterns.append({
                'type': 'project_distribution',
                'data': project_types,
                'insight': f"–ß–∞—â–µ –≤—Å–µ–≥–æ —Ä–∞–±–æ—Ç–∞—é —Å –ø—Ä–æ–µ–∫—Ç–∞–º–∏ —Ç–∏–ø–∞: {max(project_types, key=project_types.get)}"
            })
        
        return patterns
    
    def _generate_recommendations(self, results: Dict, verbose: bool) -> List[Dict[str, Any]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è"""
        recommendations = []
        
        # –ë–∞–∑–æ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations.extend([
            {
                'type': 'process_improvement',
                'title': '–°–∏—Å—Ç–µ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Ä–∞–±–æ—á–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤',
                'description': '–°–æ–∑–¥–∞—Ç—å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –¥–ª—è —á–∞—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã—Ö –∑–∞–¥–∞—á'
            },
            {
                'type': 'knowledge_management',
                'title': '–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏—è–º–∏',
                'description': '–í–µ–¥–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π —Å —Ä–µ—à–µ–Ω–∏—è–º–∏ —Ç–∏–ø–æ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º'
            }
        ])
        
        return recommendations
    
    def _calculate_task_duration(self, task_data: Dict) -> Optional[float]:
        """–†–∞—Å—á–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        return None
    
    def _assess_complexity(self, task_data: Dict) -> str:
        """–û—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞—á–∏"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ - –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å
        return "medium"
    
    def _load_reflection_log(self) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–≥–∞ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏"""
        if self.reflection_log.exists():
            try:
                with open(self.reflection_log, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                pass
        return {}
    
    def _save_analysis_results(self, results: Dict, verbose: bool):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        if verbose:
            print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞...")
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ª–æ–≥ —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏
        reflection_log = self._load_reflection_log()
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if 'sessions' not in reflection_log:
            reflection_log['sessions'] = []
        
        session = {
            'timestamp': results['timestamp'],
            'type': 'self_development',
            'insights_count': len(results['insights']),
            'patterns_count': len(results['patterns']),
            'recommendations_count': len(results['recommendations']),
            'results': results
        }
        
        reflection_log['sessions'].append(session)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ç—Ä–µ—Ñ–ª–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
        if 'reflected_tasks' not in reflection_log:
            reflection_log['reflected_tasks'] = []
        
        for insight in results['insights']:
            if insight.get('task_id'):
                if insight['task_id'] not in reflection_log['reflected_tasks']:
                    reflection_log['reflected_tasks'].append(insight['task_id'])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥
        try:
            with open(self.reflection_log, 'w', encoding='utf-8') as f:
                json.dump(reflection_log, f, ensure_ascii=False, indent=2, default=str)
            
            if verbose:
                print(f"   ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.reflection_log}")
                
        except IOError as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
    
    def _switch_to_development_context(self, verbose: bool):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ"""
        if verbose:
            print("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏–µ...")
        
        try:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞
            root_path = self.base_path.parent  # .context -> smart_layered_context
            slc_path = root_path / 'slc'
            
            if slc_path.exists():
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è —á–µ—Ä–µ–∑ CLI
                import subprocess
                result = subprocess.run(
                    [str(slc_path), 'load-context', 'self_development_system'],
                    capture_output=True,
                    text=True,
                    cwd=str(root_path)
                )
                
                if result.returncode == 0:
                    if verbose:
                        print("   ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω")
                else:
                    if verbose:
                        print("   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è")
            else:
                if verbose:
                    print("   ‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–∞–º–æ—Ä–∞–∑–≤–∏—Ç–∏—è –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
                    
        except Exception as e:
            if verbose:
                print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
                print("   ‚úÖ –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞") 