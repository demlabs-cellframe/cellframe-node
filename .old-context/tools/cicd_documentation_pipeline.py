#!/usr/bin/env python3
"""
CI/CD Documentation Pipeline
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ –ø—Ä–æ—Ü–µ—Å—Å —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
"""

import json
import os
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import datetime
# import yaml  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏

class CICDDocumentationPipeline:
    """–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ CI/CD"""
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.context_dir = self.project_root / ".context"
        self.docs_dir = self.context_dir / "docs"
        self.tools_dir = self.context_dir / "tools"
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pipeline
        self.config = {
            "validation_threshold": 85.0,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            "auto_fix": True,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
            "generate_missing": True,  # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
            "fail_on_regression": True,  # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ —Å–Ω–∏–∂–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
            "notification_webhook": None,  # Webhook –¥–ª—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
            "supported_formats": ["markdown", "json", "yaml"],
            "excluded_patterns": ["test_*", "*_test.py", "*.tmp"]
        }

    def create_github_workflow(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç GitHub Actions workflow –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        workflow_content = """name: Documentation Quality Check

on:
  push:
    branches: [ main, develop, release-* ]
    paths:
      - 'cellframe-sdk/**'
      - 'python-cellframe/**'
      - '.context/docs/**'
      - '.context/tools/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'cellframe-sdk/**'
      - 'python-cellframe/**'
      - '.context/docs/**'

jobs:
  documentation-check:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pyyaml jinja2 markdown beautifulsoup4
    
    - name: Check API changes
      id: api-check
      run: |
        python .context/tools/cicd_documentation_pipeline.py check-api-changes
        echo "api_changed=$?" >> $GITHUB_OUTPUT
    
    - name: Generate missing documentation
      if: steps.api-check.outputs.api_changed == '1'
      run: |
        python .context/tools/cicd_documentation_pipeline.py generate-missing
    
    - name: Validate documentation quality
      id: validation
      run: |
        python .context/tools/cicd_documentation_pipeline.py validate-all
        echo "quality_score=$(cat .context/analysis/quality_score.txt)" >> $GITHUB_OUTPUT
    
    - name: Auto-fix documentation issues
      if: steps.validation.outputs.quality_score < '85'
      run: |
        python .context/tools/cicd_documentation_pipeline.py auto-fix
    
    - name: Re-validate after fixes
      if: steps.validation.outputs.quality_score < '85'
      run: |
        python .context/tools/cicd_documentation_pipeline.py validate-all
    
    - name: Generate documentation report
      run: |
        python .context/tools/cicd_documentation_pipeline.py generate-report
    
    - name: Upload documentation artifacts
      uses: actions/upload-artifact@v3
      with:
        name: documentation-report
        path: |
          .context/analysis/cicd_report_*.json
          .context/analysis/documentation_validation_*.json
    
    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const report = JSON.parse(fs.readFileSync('.context/analysis/cicd_report_latest.json', 'utf8'));
          
          const comment = `## üìö Documentation Quality Report
          
          **Overall Quality Score:** ${report.quality_metrics.overall_score}%
          **Functions Documented:** ${report.coverage.documented_functions}/${report.coverage.total_functions}
          **Issues Found:** ${report.issues.total_issues}
          
          ${report.quality_metrics.overall_score >= 85 ? '‚úÖ' : '‚ö†Ô∏è'} ${report.quality_metrics.overall_score >= 85 ? 'Documentation quality meets standards' : 'Documentation quality below threshold'}
          
          ### Details
          - **API Coverage:** ${report.coverage.api_coverage}%
          - **Example Coverage:** ${report.coverage.example_coverage}%
          - **Validation Passed:** ${report.validation.passed ? 'Yes' : 'No'}
          
          [View Full Report](${report.artifacts.report_url})`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: Fail if quality below threshold
      if: steps.validation.outputs.quality_score < '85'
      run: |
        echo "Documentation quality below threshold: ${{ steps.validation.outputs.quality_score }}%"
        exit 1

  deploy-documentation:
    needs: documentation-check
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to GitHub Pages
      run: |
        python .context/tools/cicd_documentation_pipeline.py deploy-docs
"""
        
        workflow_file = self.project_root / ".github" / "workflows" / "documentation.yml"
        workflow_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(workflow_file, 'w', encoding='utf-8') as f:
            f.write(workflow_content)
        
        print(f"‚úÖ GitHub Actions workflow —Å–æ–∑–¥–∞–Ω: {workflow_file}")
        return str(workflow_file)

    def create_gitlab_pipeline(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç GitLab CI pipeline –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        pipeline_content = """stages:
  - validate
  - generate
  - deploy

variables:
  DOCUMENTATION_THRESHOLD: "85"
  PYTHON_VERSION: "3.9"

before_script:
  - python --version
  - pip install --upgrade pip
  - pip install pyyaml jinja2 markdown beautifulsoup4

validate_documentation:
  stage: validate
  script:
    - python .context/tools/cicd_documentation_pipeline.py check-api-changes
    - python .context/tools/cicd_documentation_pipeline.py validate-all
    - quality_score=$(cat .context/analysis/quality_score.txt)
    - echo "Quality score: $quality_score%"
    - |
      if (( $(echo "$quality_score < $DOCUMENTATION_THRESHOLD" | bc -l) )); then
        echo "Quality below threshold, attempting auto-fix..."
        python .context/tools/cicd_documentation_pipeline.py auto-fix
        python .context/tools/cicd_documentation_pipeline.py validate-all
        quality_score=$(cat .context/analysis/quality_score.txt)
      fi
    - |
      if (( $(echo "$quality_score < $DOCUMENTATION_THRESHOLD" | bc -l) )); then
        echo "Documentation quality still below threshold: $quality_score%"
        exit 1
      fi
  artifacts:
    reports:
      junit: .context/analysis/validation_report.xml
    paths:
      - .context/analysis/
    expire_in: 1 week
  only:
    changes:
      - cellframe-sdk/**/*
      - python-cellframe/**/*
      - .context/docs/**/*

generate_missing_docs:
  stage: generate
  script:
    - python .context/tools/cicd_documentation_pipeline.py generate-missing
    - python .context/tools/cicd_documentation_pipeline.py validate-all
  artifacts:
    paths:
      - .context/docs/
    expire_in: 1 week
  only:
    changes:
      - cellframe-sdk/**/*
      - python-cellframe/**/*
  when: manual

deploy_documentation:
  stage: deploy
  script:
    - python .context/tools/cicd_documentation_pipeline.py deploy-docs
  artifacts:
    paths:
      - public/
  only:
    - main
  when: on_success
"""
        
        pipeline_file = self.project_root / ".gitlab-ci.yml"
        
        with open(pipeline_file, 'w', encoding='utf-8') as f:
            f.write(pipeline_content)
        
        print(f"‚úÖ GitLab CI pipeline —Å–æ–∑–¥–∞–Ω: {pipeline_file}")
        return str(pipeline_file)

    def check_api_changes(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ API —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–æ–º–º–∏—Ç–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            result = subprocess.run(
                ["git", "diff", "--name-only", "HEAD~1", "HEAD"],
                cwd=self.project_root,
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è git")
                return True  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
            
            changed_files = result.stdout.strip().split('\n')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API —Ñ–∞–π–ª—ã
            api_patterns = [
                'cellframe-sdk/',
                'python-cellframe/',
                'include/',
                '.h',
                '.c'
            ]
            
            api_changed = any(
                any(pattern in file for pattern in api_patterns)
                for file in changed_files
            )
            
            if api_changed:
                print("üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ API")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                changes_file = self.context_dir / "analysis" / "api_changes.json"
                changes_file.parent.mkdir(parents=True, exist_ok=True)
                
                changes_data = {
                    "timestamp": datetime.datetime.now().isoformat(),
                    "changed_files": changed_files,
                    "api_files": [f for f in changed_files if any(p in f for p in api_patterns)]
                }
                
                with open(changes_file, 'w', encoding='utf-8') as f:
                    json.dump(changes_data, f, ensure_ascii=False, indent=2)
                
                return True
            else:
                print("‚ÑπÔ∏è –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ API –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")
                return False
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π API: {e}")
            return True

    def validate_all_documentation(self) -> Dict:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –≤—Å—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è –≤—Å–µ—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π
        validation_results = {}
        
        docs_directories = [
            self.docs_dir / "api-reference" / "top20",
            self.docs_dir / "api-reference" / "next50"
        ]
        
        total_score = 0
        total_files = 0
        
        for docs_dir in docs_directories:
            if docs_dir.exists():
                try:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
                    result = subprocess.run([
                        sys.executable,
                        str(self.tools_dir / "documentation_validator.py"),
                        "--docs-dir", str(docs_dir),
                        "--quiet"
                    ], capture_output=True, text=True, cwd=self.project_root)
                    
                    if result.returncode == 0:
                        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                        validation_files = list(self.context_dir.glob("analysis/documentation_validation_*.json"))
                        if validation_files:
                            latest_validation = sorted(validation_files)[-1]
                            with open(latest_validation, 'r', encoding='utf-8') as f:
                                validation_data = json.load(f)
                            
                            validation_results[docs_dir.name] = validation_data
                            total_score += validation_data['quality_score'] * validation_data['validated_files']
                            total_files += validation_data['validated_files']
                
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {docs_dir}: {e}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π –±–∞–ª–ª
        overall_score = total_score / total_files if total_files > 0 else 0
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–ª–ª –¥–ª—è CI/CD
        score_file = self.context_dir / "analysis" / "quality_score.txt"
        score_file.parent.mkdir(parents=True, exist_ok=True)
        with open(score_file, 'w') as f:
            f.write(f"{overall_score:.1f}")
        
        print(f"üìä –û–±—â–∏–π –±–∞–ª–ª –∫–∞—á–µ—Å—Ç–≤–∞: {overall_score:.1f}%")
        
        return {
            "overall_score": overall_score,
            "total_files": total_files,
            "directory_results": validation_results,
            "threshold_met": overall_score >= self.config["validation_threshold"]
        }

    def auto_fix_documentation(self) -> Dict:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏"""
        print("üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        fix_results = {}
        
        docs_directories = [
            self.docs_dir / "api-reference" / "top20",
            self.docs_dir / "api-reference" / "next50"
        ]
        
        for docs_dir in docs_directories:
            if docs_dir.exists():
                try:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
                    result = subprocess.run([
                        sys.executable,
                        str(self.tools_dir / "documentation_fixer.py"),
                        "--docs-dir", str(docs_dir)
                    ], capture_output=True, text=True, cwd=self.project_root)
                    
                    if result.returncode == 0:
                        print(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –¥–ª—è {docs_dir.name}")
                        fix_results[docs_dir.name] = {"status": "success", "output": result.stdout}
                    else:
                        print(f"‚ùå –û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è {docs_dir.name}: {result.stderr}")
                        fix_results[docs_dir.name] = {"status": "error", "error": result.stderr}
                
                except Exception as e:
                    print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ {docs_dir}: {e}")
                    fix_results[docs_dir.name] = {"status": "exception", "error": str(e)}
        
        return fix_results

    def generate_missing_documentation(self) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        print("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        generation_results = {}
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–∏—Ç—å API –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å
            api_inventory = self.context_dir / "analysis" / "cellframe_api_inventory.json"
            if not api_inventory.exists() or self.check_api_changes():
                print("üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ API –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è...")
                result = subprocess.run([
                    sys.executable,
                    str(self.tools_dir / "cellframe_api_extractor.py")
                ], capture_output=True, text=True, cwd=self.project_root)
                
                if result.returncode != 0:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è API –∏–Ω–≤–µ–Ω—Ç–∞—Ä—è: {result.stderr}")
                    return {"status": "error", "error": "Failed to update API inventory"}
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
            if not (self.docs_dir / "api-reference" / "next50").exists():
                print("üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–∏—Ö 50 —Ñ—É–Ω–∫—Ü–∏–π...")
                result = subprocess.run([
                    sys.executable,
                    str(self.tools_dir / "next50_functions_generator.py")
                ], capture_output=True, text=True, cwd=self.project_root)
                
                if result.returncode == 0:
                    generation_results["next50"] = {"status": "generated", "output": result.stdout}
                else:
                    generation_results["next50"] = {"status": "error", "error": result.stderr}
            
            return generation_results
            
        except Exception as e:
            return {"status": "exception", "error": str(e)}

    def generate_cicd_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç –¥–ª—è CI/CD"""
        print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ CI/CD...")
        
        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        validation_results = self.validate_all_documentation()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        total_functions = 0
        documented_functions = 0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º API –∏–Ω–≤–µ–Ω—Ç–∞—Ä—å
        api_inventory = self.context_dir / "analysis" / "cellframe_api_inventory.json"
        if api_inventory.exists():
            with open(api_inventory, 'r', encoding='utf-8') as f:
                api_data = json.load(f)
                total_functions = api_data['metadata']['total_functions']
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
        for docs_dir in ["top20", "next50"]:
            docs_path = self.docs_dir / "api-reference" / docs_dir
            if docs_path.exists():
                documented_functions += len(list(docs_path.glob("*.md"))) - 1  # –ò—Å–∫–ª—é—á–∞–µ–º README.md
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
        report = {
            "timestamp": datetime.datetime.now().isoformat(),
            "pipeline_version": "1.0.0",
            "quality_metrics": {
                "overall_score": validation_results.get("overall_score", 0),
                "threshold": self.config["validation_threshold"],
                "threshold_met": validation_results.get("threshold_met", False)
            },
            "coverage": {
                "total_functions": total_functions,
                "documented_functions": documented_functions,
                "api_coverage": (documented_functions / total_functions * 100) if total_functions > 0 else 0,
                "example_coverage": 100 if documented_functions > 0 else 0  # –í—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–º–µ—é—Ç –ø—Ä–∏–º–µ—Ä—ã
            },
            "validation": {
                "passed": validation_results.get("threshold_met", False),
                "total_files": validation_results.get("total_files", 0),
                "directory_results": validation_results.get("directory_results", {})
            },
            "issues": {
                "total_issues": sum(
                    result.get("issues_found", 0) 
                    for result in validation_results.get("directory_results", {}).values()
                ),
                "critical_issues": 0,  # TODO: –î–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º
                "auto_fixed": 0  # TODO: –î–æ–±–∞–≤–∏—Ç—å —Å—á–µ—Ç—á–∏–∫ –∞–≤—Ç–æ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
            },
            "artifacts": {
                "report_url": f"https://github.com/{os.environ.get('GITHUB_REPOSITORY', 'cellframe/cellframe-node')}/actions",
                "documentation_url": "https://wiki.cellframe.net"
            },
            "recommendations": self.generate_recommendations(validation_results)
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.context_dir / "analysis" / f"cicd_report_{timestamp}.json"
        report_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–º–ª–∏–Ω–∫ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ—Ç—á–µ—Ç
        latest_link = self.context_dir / "analysis" / "cicd_report_latest.json"
        if latest_link.exists():
            latest_link.unlink()
        latest_link.symlink_to(report_file.name)
        
        print(f"üìã –û—Ç—á–µ—Ç CI/CD —Å–æ–∑–¥–∞–Ω: {report_file}")
        return str(report_file)

    def generate_recommendations(self, validation_results: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        recommendations = []
        
        overall_score = validation_results.get("overall_score", 0)
        
        if overall_score < 70:
            recommendations.append("–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ - —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ")
            recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—É—é —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏")
        elif overall_score < 85:
            recommendations.append("–ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞ - —Ç—Ä–µ–±—É—é—Ç—Å—è —É–ª—É—á—à–µ–Ω–∏—è")
            recommendations.append("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º")
        else:
            recommendations.append("–ö–∞—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º")
            recommendations.append("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ —Ç–µ–∫—É—â–∏–π —É—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ
        total_files = validation_results.get("total_files", 0)
        if total_files < 50:
            recommendations.append("–ù–∏–∑–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")
        
        return recommendations

    def deploy_documentation(self) -> bool:
        """–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        print("üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–∞–π—Ç
            public_dir = self.project_root / "public"
            public_dir.mkdir(exist_ok=True)
            
            # –ö–æ–ø–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
            import shutil
            
            docs_source = self.docs_dir / "api-reference"
            docs_target = public_dir / "api-reference"
            
            if docs_target.exists():
                shutil.rmtree(docs_target)
            
            shutil.copytree(docs_source, docs_target)
            
            # –°–æ–∑–¥–∞–µ–º –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            index_content = """<!DOCTYPE html>
<html>
<head>
    <title>Cellframe API Documentation</title>
    <meta charset="utf-8">
    <style>
        body { font-family: Arial, sans-serif; margin: 40px; }
        .header { background: #f0f0f0; padding: 20px; border-radius: 5px; }
        .section { margin: 20px 0; }
        a { color: #0066cc; text-decoration: none; }
        a:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <div class="header">
        <h1>Cellframe API Documentation</h1>
        <p>–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API</p>
    </div>
    
    <div class="section">
        <h2>–†–∞–∑–¥–µ–ª—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏</h2>
        <ul>
            <li><a href="api-reference/top20/">–¢–æ–ø-20 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π</a></li>
            <li><a href="api-reference/next50/">–°–ª–µ–¥—É—é—â–∏–µ 50 —Ñ—É–Ω–∫—Ü–∏–π</a></li>
        </ul>
    </div>
    
    <div class="section">
        <h2>–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ</h2>
        <p>""" + datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S") + """</p>
    </div>
</body>
</html>"""
            
            with open(public_dir / "index.html", 'w', encoding='utf-8') as f:
                f.write(index_content)
            
            print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–∞ –≤ {public_dir}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è: {e}")
            return False

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='CI/CD Documentation Pipeline')
    parser.add_argument('command', choices=[
        'setup-github', 'setup-gitlab', 'check-api-changes', 
        'validate-all', 'auto-fix', 'generate-missing', 
        'generate-report', 'deploy-docs'
    ])
    parser.add_argument('--config', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    
    args = parser.parse_args()
    
    pipeline = CICDDocumentationPipeline()
    
    if args.command == 'setup-github':
        pipeline.create_github_workflow()
    elif args.command == 'setup-gitlab':
        pipeline.create_gitlab_pipeline()
    elif args.command == 'check-api-changes':
        changed = pipeline.check_api_changes()
        sys.exit(1 if changed else 0)
    elif args.command == 'validate-all':
        results = pipeline.validate_all_documentation()
        sys.exit(0 if results['threshold_met'] else 1)
    elif args.command == 'auto-fix':
        pipeline.auto_fix_documentation()
    elif args.command == 'generate-missing':
        pipeline.generate_missing_documentation()
    elif args.command == 'generate-report':
        pipeline.generate_cicd_report()
    elif args.command == 'deploy-docs':
        success = pipeline.deploy_documentation()
        sys.exit(0 if success else 1)

if __name__ == '__main__':
    main() 