#!/usr/bin/env python3
"""
Detailed Issue Analyzer for Python Cellframe
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º –≤ Python Cellframe
"""

import os
import re
import json
from pathlib import Path
from datetime import datetime

def analyze_error_handling_issues():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫"""
    print("üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫...")
    
    issues = []
    base_path = Path("python-cellframe")
    
    for c_file in base_path.rglob("*.c"):
        try:
            with open(c_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except:
            continue
        
        # –ò—â–µ–º PyErr_SetString –±–µ–∑ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ return NULL
        for i, line in enumerate(lines):
            if 'PyErr_SetString' in line:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 3 —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ return NULL
                next_lines = '\n'.join(lines[i+1:i+4])
                if 'return NULL' not in next_lines and 'return' not in next_lines:
                    issues.append({
                        "file": str(c_file),
                        "line": i + 1,
                        "issue": "Missing return NULL after PyErr_SetString",
                        "code": line.strip(),
                        "severity": "HIGH",
                        "fix": "Add 'return NULL;' after error setting"
                    })
    
    return issues

def analyze_memory_management():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é"""
    print("üîç –ê–Ω–∞–ª–∏–∑ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é...")
    
    issues = []
    base_path = Path("python-cellframe")
    
    for c_file in base_path.rglob("*.c"):
        try:
            with open(c_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except:
            continue
        
        # –ò—â–µ–º malloc –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ NULL
        for i, line in enumerate(lines):
            if re.search(r'=\s*malloc\s*\(|=\s*calloc\s*\(|=\s*realloc\s*\(', line):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ 5 —Å—Ç—Ä–æ–∫ –Ω–∞ –ø—Ä–æ–≤–µ—Ä–∫—É NULL
                next_lines = '\n'.join(lines[i+1:i+6])
                if 'if' not in next_lines or 'NULL' not in next_lines:
                    issues.append({
                        "file": str(c_file),
                        "line": i + 1,
                        "issue": "malloc/calloc result not checked for NULL",
                        "code": line.strip(),
                        "severity": "HIGH",
                        "fix": "Add NULL check: if (ptr == NULL) { handle error; }"
                    })
        
        # –ò—â–µ–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —É—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏
        malloc_lines = []
        free_lines = []
        
        for i, line in enumerate(lines):
            if re.search(r'malloc\s*\(|calloc\s*\(|realloc\s*\(', line):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                var_match = re.search(r'(\w+)\s*=.*(?:malloc|calloc|realloc)', line)
                if var_match:
                    malloc_lines.append((i + 1, var_match.group(1)))
            
            if 'free(' in line:
                var_match = re.search(r'free\s*\(\s*(\w+)\s*\)', line)
                if var_match:
                    free_lines.append((i + 1, var_match.group(1)))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ malloc/free
        malloc_vars = {var for _, var in malloc_lines}
        free_vars = {var for _, var in free_lines}
        
        unfreed_vars = malloc_vars - free_vars
        for line_num, var in malloc_lines:
            if var in unfreed_vars:
                issues.append({
                    "file": str(c_file),
                    "line": line_num,
                    "issue": f"Potential memory leak: variable '{var}' allocated but not freed",
                    "code": lines[line_num - 1].strip() if line_num <= len(lines) else "",
                    "severity": "MEDIUM",
                    "fix": f"Add free({var}); before function returns"
                })
    
    return issues

def analyze_thread_safety():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã thread safety"""
    print("üîç –ê–Ω–∞–ª–∏–∑ thread safety...")
    
    issues = []
    base_path = Path("python-cellframe")
    
    for c_file in base_path.rglob("*.c"):
        try:
            with open(c_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except:
            continue
        
        # –ò—â–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        for i, line in enumerate(lines):
            if re.search(r'static\s+(?!const)\w+.*=', line):
                # –ò—Å–∫–ª—é—á–∞–µ–º –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏
                if 'const' not in line and '(' not in line:
                    issues.append({
                        "file": str(c_file),
                        "line": i + 1,
                        "issue": "Non-const static variable may cause thread safety issues",
                        "code": line.strip(),
                        "severity": "MEDIUM",
                        "fix": "Consider thread-local storage (__thread) or proper synchronization"
                    })
    
    return issues

def analyze_api_consistency():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å API"""
    print("üîç –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ API...")
    
    issues = []
    base_path = Path("python-cellframe")
    api_functions = {}
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ API —Ñ—É–Ω–∫—Ü–∏–∏
    for c_file in base_path.rglob("*.c"):
        try:
            with open(c_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        except:
            continue
        
        # –ò—â–µ–º PyMethodDef —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        method_matches = re.finditer(r'{\s*"(\w+)"\s*,\s*(\w+)\s*,\s*(METH_\w+)', content)
        for match in method_matches:
            func_name = match.group(1)
            c_func_name = match.group(2)
            method_type = match.group(3)
            
            if func_name not in api_functions:
                api_functions[func_name] = []
            
            api_functions[func_name].append({
                "file": str(c_file),
                "c_function": c_func_name,
                "method_type": method_type
            })
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
    naming_patterns = {}
    for func_name in api_functions.keys():
        if '_' in func_name:
            prefix = func_name.split('_')[0]
            if prefix not in naming_patterns:
                naming_patterns[prefix] = []
            naming_patterns[prefix].append(func_name)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
    for prefix, funcs in naming_patterns.items():
        if len(funcs) > 1:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∏–ª–∏ –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è
            snake_case = [f for f in funcs if f.islower() and '_' in f]
            camel_case = [f for f in funcs if any(c.isupper() for c in f[1:])]
            
            if snake_case and camel_case:
                issues.append({
                    "file": "API",
                    "line": 0,
                    "issue": f"Mixed naming styles in {prefix} functions",
                    "code": f"snake_case: {snake_case[:3]}, camelCase: {camel_case[:3]}",
                    "severity": "LOW",
                    "fix": "Standardize on one naming convention (prefer snake_case)"
                })
    
    return issues

def analyze_performance_issues():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("üîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
    
    issues = []
    base_path = Path("python-cellframe")
    
    for c_file in base_path.rglob("*.c"):
        try:
            with open(c_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
        except:
            continue
        
        # –ò—â–µ–º –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        for i, line in enumerate(lines):
            # –ß–∞—Å—Ç—ã–µ –≤—ã–∑–æ–≤—ã PyUnicode_AsUTF8 –≤ —Ü–∏–∫–ª–∞—Ö
            if 'for' in line.lower() and i + 5 < len(lines):
                loop_body = '\n'.join(lines[i:i+5])
                if loop_body.count('PyUnicode_AsUTF8') > 1:
                    issues.append({
                        "file": str(c_file),
                        "line": i + 1,
                        "issue": "Multiple PyUnicode_AsUTF8 calls in loop",
                        "code": line.strip(),
                        "severity": "MEDIUM",
                        "fix": "Cache string conversion outside loop"
                    })
            
            # –ò–∑–±—ã—Ç–æ—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏–ø–æ–≤
            if line.count('PyObject_Type') > 1:
                issues.append({
                    "file": str(c_file),
                    "line": i + 1,
                    "issue": "Multiple type checks on same line",
                    "code": line.strip(),
                    "severity": "LOW",
                    "fix": "Cache type check result"
                })
            
            # –ù–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—è —Å—Ç—Ä–æ–∫
            if 'PyUnicode_Concat' in line and ('for' in lines[max(0, i-3):i] or 'while' in lines[max(0, i-3):i]):
                issues.append({
                    "file": str(c_file),
                    "line": i + 1,
                    "issue": "String concatenation in loop",
                    "code": line.strip(),
                    "severity": "MEDIUM",
                    "fix": "Use PyUnicode_Join or build list first"
                })
    
    return issues

def generate_detailed_report():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º –ø—Ä–æ–±–ª–µ–º–∞–º"""
    print("üìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
    
    report = {
        "timestamp": datetime.now().isoformat(),
        "analysis_categories": {
            "error_handling": analyze_error_handling_issues(),
            "memory_management": analyze_memory_management(),
            "thread_safety": analyze_thread_safety(),
            "api_consistency": analyze_api_consistency(),
            "performance": analyze_performance_issues()
        }
    }
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_issues = sum(len(issues) for issues in report["analysis_categories"].values())
    
    severity_counts = {
        "HIGH": 0,
        "MEDIUM": 0,
        "LOW": 0
    }
    
    for category_issues in report["analysis_categories"].values():
        for issue in category_issues:
            severity_counts[issue["severity"]] += 1
    
    report["summary"] = {
        "total_issues": total_issues,
        "severity_breakdown": severity_counts,
        "categories_breakdown": {
            category: len(issues) 
            for category, issues in report["analysis_categories"].items()
        }
    }
    
    return report

def create_refactoring_tasks():
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –¥–ª—è —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞"""
    print("üìù –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–¥–∞—á —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞...")
    
    report = generate_detailed_report()
    
    tasks = {
        "immediate_fixes": [],
        "short_term": [],
        "long_term": []
    }
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∑–∞–¥–∞—á–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
    for category, issues in report["analysis_categories"].items():
        for issue in issues:
            task = {
                "category": category,
                "file": Path(issue["file"]).name,
                "line": issue["line"],
                "description": issue["issue"],
                "fix": issue["fix"],
                "estimated_time": "30min" if issue["severity"] == "HIGH" else "15min"
            }
            
            if issue["severity"] == "HIGH":
                tasks["immediate_fixes"].append(task)
            elif issue["severity"] == "MEDIUM":
                tasks["short_term"].append(task)
            else:
                tasks["long_term"].append(task)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∑–∞–¥–∞—á–∏
    tasks["architectural_improvements"] = [
        {
            "category": "architecture",
            "description": "–°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—É—é —Å–∏—Å—Ç–µ–º—É error handling",
            "estimated_time": "2-3 –¥–Ω—è",
            "priority": "HIGH"
        },
        {
            "category": "architecture", 
            "description": "–í–Ω–µ–¥—Ä–∏—Ç—å RAII –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é",
            "estimated_time": "1 –Ω–µ–¥–µ–ª—è",
            "priority": "MEDIUM"
        },
        {
            "category": "architecture",
            "description": "–°–æ–∑–¥–∞—Ç—å thread-safe API wrapper",
            "estimated_time": "3-5 –¥–Ω–µ–π",
            "priority": "MEDIUM"
        },
        {
            "category": "testing",
            "description": "–î–æ–±–∞–≤–∏—Ç—å unit —Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö API —Ñ—É–Ω–∫—Ü–∏–π",
            "estimated_time": "2 –Ω–µ–¥–µ–ª–∏",
            "priority": "HIGH"
        },
        {
            "category": "documentation",
            "description": "–°–æ–∑–¥–∞—Ç—å API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏",
            "estimated_time": "1 –Ω–µ–¥–µ–ª—è",
            "priority": "MEDIUM"
        }
    ]
    
    return tasks

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    if not Path("python-cellframe").exists():
        print("‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è python-cellframe –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return 1
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    report = generate_detailed_report()
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞
    tasks = create_refactoring_tasks()
    
    # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
    print("\nüìä –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ Python Cellframe:")
    print(f"   ‚ö†Ô∏è  –í—Å–µ–≥–æ –ø—Ä–æ–±–ª–µ–º: {report['summary']['total_issues']}")
    print(f"   üî¥ –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {report['summary']['severity_breakdown']['HIGH']}")
    print(f"   üü° –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {report['summary']['severity_breakdown']['MEDIUM']}")
    print(f"   üü¢ –ù–∏–∑–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {report['summary']['severity_breakdown']['LOW']}")
    
    print("\nüìã –ü—Ä–æ–±–ª–µ–º—ã –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
    for category, count in report['summary']['categories_breakdown'].items():
        print(f"   ‚Ä¢ {category}: {count} –ø—Ä–æ–±–ª–µ–º")
    
    print(f"\nüö® –ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {len(tasks['immediate_fixes'])} –∑–∞–¥–∞—á")
    print(f"üìÖ –ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ: {len(tasks['short_term'])} –∑–∞–¥–∞—á")
    print(f"üéØ –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ: {len(tasks['long_term'])} –∑–∞–¥–∞—á")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç—ã
    output_dir = Path(".context/analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    with open(output_dir / "detailed_issues_report.json", 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    with open(output_dir / "refactoring_tasks.json", 'w', encoding='utf-8') as f:
        json.dump(tasks, f, ensure_ascii=False, indent=2)
    
    print(f"\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_dir / 'detailed_issues_report.json'}")
    print(f"üìã –ó–∞–¥–∞—á–∏ —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥–∞: {output_dir / 'refactoring_tasks.json'}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-5 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º
    if tasks['immediate_fixes']:
        print("\nüî• –¢–æ–ø-5 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º:")
        for i, task in enumerate(tasks['immediate_fixes'][:5], 1):
            print(f"   {i}. {task['file']}:{task['line']} - {task['description']}")
    
    return 0

if __name__ == '__main__':
    exit(main()) 